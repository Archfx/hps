{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f479b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# start: only 1 BS engine\n",
    "# assuptions:\n",
    "# Assumptions\n",
    "# - 1 unique key per job\n",
    "# Pattern is Linear Ops -> PBSs\n",
    "# 1 param set for all jobs\n",
    "# Static scheduler\n",
    "# No need to schedule Noise management (PBS are inserted already as needed)\n",
    "# (6. Schoolbook addition/Multiplication/Comparison Patterns)\n",
    "\n",
    "# - BS engine can only work with one specific parameterset, so keys can be different but their sizes are known in advance\n",
    "# - and therefore the key loading time is also known in advance\n",
    "# - BS engines that share jobs must also use the same parameter sets, otherwise it would not make any sense\n",
    "# - BS engine does not handle scalar MulAdds, as required for scaling and the keyswitch\n",
    "# we assume that all jobs are dynamic, so they produce in-between results and the PBS needed for noise management were inserted by a compiler\n",
    "\n",
    "# all PBS functions can be brought to full precision by 1 batch pause (because need to do scaling in the background), then 4 PBS in a batch, then 1 batch pause (accumulate the result)\n",
    "# --> we simply model that as one PBS call\n",
    "\n",
    "# Advanced aspects:\n",
    "# - BS engine that can handle different parameter sets\n",
    "# - dynamic noise management: the schduler needs to add PBS for noise management\n",
    "\n",
    "key_freespace_indicator = -1\n",
    "batch_freespace_indicator = -1\n",
    "global_tic_cnt = 0 # incremented by scheduler\n",
    "\n",
    "# TODO: model jobs as having single-file-codepieces and vectorized codepieces for batching, what that exactly looks like depends on the use case, good coding will vectorize more\n",
    "# need to respect flexibilities --> need DAGs\n",
    "# need to respect fairness\n",
    "# scheduling is a closed problem, need literature research\n",
    "# maybe go for multiple PBS engine scheduling? But perhaps too difficult in practice as in-between-results must be shared\n",
    "\n",
    "class TFHE_sub_job:\n",
    "    # a sub_job is a part of a job that leads to an in-between result that other jobs might wait for\n",
    "    def __init__(self, parallelizeable_calls_array, key_idx):\n",
    "        # parallelizeable_calls_array for each \"step\" of the job computation, this array shows how many PBS calls can de done\n",
    "        # indepentendly and therefore in parallel\n",
    "        self.key_idx = key_idx\n",
    "        self.parallelizeable_calls_array = np.array(parallelizeable_calls_array)\n",
    "        self.parall_array_temp = np.array(parallelizeable_calls_array)\n",
    "        self.parall_arr_idx = 0\n",
    "        self.maketime = -1\n",
    "        self.age = 0\n",
    "        self.done = False\n",
    "        self.best_maketime_to_completion = -1\n",
    "    \n",
    "    def get_best_maketime(self, batchsize): # in batches, since 1 batch = 1 time unit, batches are a time unit\n",
    "        return sum(np.ceil(self.parallelizeable_calls_array/batchsize))\n",
    "    \n",
    "    def get_best_maketime_to_completion(self, batchsize): # in batches, since 1 batch = 1 time unit, batches are a time unit\n",
    "        return sum(np.ceil(self.parall_array_temp/batchsize))\n",
    "    \n",
    "    def inc_age(self):\n",
    "        # scheduler must increase the age until the job is done\n",
    "        if sum(self.parall_array_temp) != 0:\n",
    "            self.age += 1\n",
    "\n",
    "    def serve_pbs(self, cnt):\n",
    "        cnts_left = self.parall_array_temp[self.parall_arr_idx]\n",
    "        unused_cnts = 0\n",
    "        if cnts_left > cnt:\n",
    "            self.parall_array_temp[self.parall_arr_idx] -= cnt\n",
    "        else:\n",
    "            self.parall_array_temp[self.parall_arr_idx] = 0\n",
    "            unused_cnts = cnt - cnts_left\n",
    "            if self.parall_arr_idx+1 < len(self.parallelizeable_calls_array):\n",
    "                self.parall_arr_idx += 1\n",
    "            else:\n",
    "                # list empty = job done\n",
    "                self.done=True\n",
    "                self.maketime = self.age\n",
    "                # sanity check\n",
    "                checksum = sum(self.parall_array_temp)\n",
    "                if checksum != 0:\n",
    "                    print(\"Error: job finished with \" + checksum + \" leftover PBS calls - this is not supposed to happen, something went wrong\")\n",
    "        return unused_cnts\n",
    "\n",
    "class PBS_engine:\n",
    "    def __init__(self, pbs_per_s, batchsize, key_loading_time, max_num_keys):\n",
    "        self.speed = pbs_per_s\n",
    "        self.batchsize = batchsize\n",
    "        self.key_loading_time = key_loading_time # in batches per second\n",
    "        self.max_num_keys = max_num_keys\n",
    "\n",
    "        self.key_storage = np.ones(max_num_keys)*key_freespace_indicator # this array stores the indices of the keys that are present on the device\n",
    "        self.batch = np.ones(batchsize)*batch_freespace_indicator\n",
    "        self.wasted_batchslots = 0\n",
    "        self.new_key_storage = np.ones(max_num_keys)\n",
    "        self.key_loading_cooldown = 0\n",
    "\n",
    "    def run(self):\n",
    "        self.wasted_batchslots += len(np.argwhere(self.batch==batch_freespace_indicator))\n",
    "        # empty batch\n",
    "        self.batch = np.ones(self.batchsize)*batch_freespace_indicator\n",
    "        # update key storage\n",
    "        if self.key_loading_cooldown > 0:\n",
    "            self.key_loading_cooldown -= 1\n",
    "        else:\n",
    "            self.key_storage = self.new_key_storage\n",
    "        # TODO: fill batch anew\n",
    "\n",
    "    def add_to_batch(self, num_ciphertexts, key_idx):\n",
    "        # only allow to fill batch with ciphertexts that we have the keys for\n",
    "        if len(np.argwhere(self.key_storage==key_idx)) > 0:\n",
    "            # is there still space in the batch?\n",
    "            indices = np.argwhere(self.batch==batch_freespace_indicator)\n",
    "            if len(indices) > num_ciphertexts:\n",
    "                for i in range(num_ciphertexts):\n",
    "                    self.key_storage[indices[i]] = key_idx\n",
    "            else:\n",
    "                print(\"Error: could not add to batch ciphertext of key \" + key_idx + \" - reason: batch capacity insufficient\")\n",
    "        else:\n",
    "            print(\"Error: could not add batch with key \" + key_idx + \" - reason: key not present - load the key first\")\n",
    "\n",
    "    def unload_key(self, key_idx):\n",
    "        indice = np.argwhere(self.key_storage==key_idx)\n",
    "        # we expect the key to be present on the device only once\n",
    "        if len(indice) > 0:\n",
    "            self.new_key_storage[indice[0]]=key_freespace_indicator\n",
    "        else:\n",
    "            # this is unexpected\n",
    "            print(\"Warning: could not unload key \" + key_idx + \" - reason: key not present\")\n",
    "\n",
    "    def load_key(self, key_idx):\n",
    "        # are we already loading a key?\n",
    "        if self.key_loading_cooldown == 0:\n",
    "            # is there still space?\n",
    "            indices = np.argwhere(self.key_storage==key_freespace_indicator)\n",
    "            if len(indices) > 0:\n",
    "                # is the key already present on the device?\n",
    "                if len(np.argwhere(self.key_storage==key_idx)) > 0:\n",
    "                    print(\"Warning: key \" + key_idx + \" - is already present, did not load again\")\n",
    "                else:\n",
    "                    self.new_key_storage[indices[0]] = key_idx\n",
    "                    self.key_loading_cooldown = self.key_loading_time\n",
    "            else:\n",
    "                # need to overwrite some key\n",
    "                # yes, could do complicated logic here but we trust that after a job is done the unloading function is called\n",
    "                print(\"Error: could not load key \" + key_idx + \" - reason: key storage full - unload a key first\")\n",
    "        else:\n",
    "                print(\"Error: could not load key \" + key_idx + \" - reason: a key is already being loaded\")\n",
    "\n",
    "# scheduler\n",
    "# given a list of sub_jobs, sorted by priority metric, and a PBS_engine, give jobs to the engine\n",
    "# strategy: focus jobs for better latency in a certain priority, only use other jobs to fill up leftover spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eebb6f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.arange(5)\n",
    "np.ceil(test/5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
